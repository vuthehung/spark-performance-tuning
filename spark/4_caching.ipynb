{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e02171b5-8b8d-4b81-8826-2fb3ee1a8a24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.driver.memory\", \"10g\")\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"268435456\")\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_file = \"../data/data_skew/customers.parquet\"\n",
    "df_customers = spark.read.parquet(customers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+---+------+----------+-----+-----------+\n",
      "|cust_id   |name         |age|gender|birthday  |zip  |city       |\n",
      "+----------+-------------+---+------+----------+-----+-----------+\n",
      "|C007YEYTX9|Aaron Abbott |34 |Female|7/13/1991 |97823|boston     |\n",
      "|C00B971T1J|Aaron Austin |37 |Female|12/16/2004|30332|chicago    |\n",
      "|C00WRSJF1Q|Aaron Barnes |29 |Female|3/11/1977 |23451|denver     |\n",
      "|C01AZWQMF3|Aaron Barrett|31 |Male  |7/9/1998  |46613|los_angeles|\n",
      "|C01BKUFRHA|Aaron Becker |54 |Male  |11/24/1979|40284|san_diego  |\n",
      "+----------+-------------+---+------+----------+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customers.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cust_id: string, name: string, age: string, gender: string, birthday: string, zip: string, city: string, customer_group: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+---+------+---------+-----+------+--------------+\n",
      "|cust_id   |name          |age|gender|birthday |zip  |city  |customer_group|\n",
      "+----------+--------------+---+------+---------+-----+------+--------------+\n",
      "|C007YEYTX9|Aaron Abbott  |34 |Female|7/13/1991|97823|boston|mid           |\n",
      "|C08XAQUY73|Aaron Lambert |54 |Female|11/5/1966|75218|boston|old           |\n",
      "|C094P1VXF9|Aaron Lindsey |24 |Male  |9/21/1990|29399|boston|young         |\n",
      "|C097SHE1EF|Aaron Lopez   |22 |Female|4/18/2001|82129|boston|young         |\n",
      "|C0DTC6436T|Aaron Schwartz|52 |Female|7/9/1962 |57192|boston|old           |\n",
      "+----------+--------------+---+------+---------+-----+------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_base = (\n",
    "    df_customers\n",
    "    .filter(F.col(\"city\") == \"boston\")\n",
    "    .withColumn(\n",
    "        \"customer_group\", \n",
    "        F.when(\n",
    "            F.col(\"age\").between(20, 30), \n",
    "            F.lit(\"young\") \n",
    "        )\n",
    "        .when(\n",
    "            F.col(\"age\").between(31, 50), \n",
    "            F.lit(\"mid\") \n",
    "        )\n",
    "        .when(\n",
    "            F.col(\"age\") > 51, \n",
    "            F.lit(\"old\") \n",
    "        )\n",
    "        .otherwise(F.lit(\"kid\"))\n",
    "     )\n",
    "    .select(\"cust_id\", \"name\", \"age\", \"gender\", \"birthday\", \"zip\", \"city\", \"customer_group\")\n",
    ")\n",
    "\n",
    "df_base.cache() \n",
    "df_base.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_1#307, split('birthday, /, -1)[2] AS birth_year#317]\n",
      "+- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_1 AS test_column_1#307]\n",
      "   +- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57]\n",
      "      +- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, CASE WHEN ((cast(age#45 as int) >= 20) AND (cast(age#45 as int) <= 30)) THEN young WHEN ((cast(age#45 as int) >= 31) AND (cast(age#45 as int) <= 50)) THEN mid WHEN (cast(age#45 as int) > 51) THEN old ELSE kid END AS customer_group#57]\n",
      "         +- Filter (city#49 = boston)\n",
      "            +- Relation [cust_id#43,name#44,age#45,gender#46,birthday#47,zip#48,city#49] parquet\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "cust_id: string, name: string, age: string, gender: string, birthday: string, zip: string, city: string, customer_group: string, test_column_1: string, birth_year: string\n",
      "Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_1#307, split(birthday#47, /, -1)[2] AS birth_year#317]\n",
      "+- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_1 AS test_column_1#307]\n",
      "   +- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57]\n",
      "      +- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, CASE WHEN ((cast(age#45 as int) >= 20) AND (cast(age#45 as int) <= 30)) THEN young WHEN ((cast(age#45 as int) >= 31) AND (cast(age#45 as int) <= 50)) THEN mid WHEN (cast(age#45 as int) > 51) THEN old ELSE kid END AS customer_group#57]\n",
      "         +- Filter (city#49 = boston)\n",
      "            +- Relation [cust_id#43,name#44,age#45,gender#46,birthday#47,zip#48,city#49] parquet\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_1 AS test_column_1#307, split(birthday#47, /, -1)[2] AS birth_year#317]\n",
      "+- InMemoryRelation [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "      +- *(1) Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, CASE WHEN ((cast(age#45 as int) >= 20) AND (cast(age#45 as int) <= 30)) THEN young WHEN ((cast(age#45 as int) >= 31) AND (cast(age#45 as int) <= 50)) THEN mid WHEN (cast(age#45 as int) > 51) THEN old ELSE kid END AS customer_group#57]\n",
      "         +- *(1) Filter (isnotnull(city#49) AND (city#49 = boston))\n",
      "            +- *(1) ColumnarToRow\n",
      "               +- FileScan parquet [cust_id#43,name#44,age#45,gender#46,birthday#47,zip#48,city#49] Batched: true, DataFilters: [isnotnull(city#49), (city#49 = boston)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/afaqueahmad/Documents/youtube/spark-experiments/data/data_..., PartitionFilters: [], PushedFilters: [IsNotNull(city), EqualTo(city,boston)], ReadSchema: struct<cust_id:string,name:string,age:string,gender:string,birthday:string,zip:string,city:string>\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_1 AS test_column_1#307, split(birthday#47, /, -1)[2] AS birth_year#317]\n",
      "+- InMemoryTableScan [age#45, birthday#47, city#49, cust_id#43, customer_group#57, gender#46, name#44, zip#48]\n",
      "      +- InMemoryRelation [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- *(1) Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, CASE WHEN ((cast(age#45 as int) >= 20) AND (cast(age#45 as int) <= 30)) THEN young WHEN ((cast(age#45 as int) >= 31) AND (cast(age#45 as int) <= 50)) THEN mid WHEN (cast(age#45 as int) > 51) THEN old ELSE kid END AS customer_group#57]\n",
      "               +- *(1) Filter (isnotnull(city#49) AND (city#49 = boston))\n",
      "                  +- *(1) ColumnarToRow\n",
      "                     +- FileScan parquet [cust_id#43,name#44,age#45,gender#46,birthday#47,zip#48,city#49] Batched: true, DataFilters: [isnotnull(city#49), (city#49 = boston)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/afaqueahmad/Documents/youtube/spark-experiments/data/data_..., PartitionFilters: [], PushedFilters: [IsNotNull(city), EqualTo(city,boston)], ReadSchema: struct<cust_id:string,name:string,age:string,gender:string,birthday:string,zip:string,city:string>\n",
      "\n",
      "+----------+--------------+---+------+---------+-----+------+--------------+-------------+----------+\n",
      "|cust_id   |name          |age|gender|birthday |zip  |city  |customer_group|test_column_1|birth_year|\n",
      "+----------+--------------+---+------+---------+-----+------+--------------+-------------+----------+\n",
      "|C007YEYTX9|Aaron Abbott  |34 |Female|7/13/1991|97823|boston|mid           |test_column_1|1991      |\n",
      "|C08XAQUY73|Aaron Lambert |54 |Female|11/5/1966|75218|boston|old           |test_column_1|1966      |\n",
      "|C094P1VXF9|Aaron Lindsey |24 |Male  |9/21/1990|29399|boston|young         |test_column_1|1990      |\n",
      "|C097SHE1EF|Aaron Lopez   |22 |Female|4/18/2001|82129|boston|young         |test_column_1|2001      |\n",
      "|C0DTC6436T|Aaron Schwartz|52 |Female|7/9/1962 |57192|boston|old           |test_column_1|1962      |\n",
      "+----------+--------------+---+------+---------+-----+------+--------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = (\n",
    "    df_base\n",
    "    .withColumn(\"test_column_1\", F.lit(\"test_column_1\"))\n",
    "    .withColumn(\"birth_year\", F.split(\"birthday\", \"/\").getItem(2))\n",
    ")\n",
    "\n",
    "df1.explain(True)\n",
    "df1.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_2#649, split('birthday, /, -1)[1] AS birth_month#659]\n",
      "+- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_2 AS test_column_2#649]\n",
      "   +- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57]\n",
      "      +- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, CASE WHEN ((cast(age#45 as int) >= 20) AND (cast(age#45 as int) <= 30)) THEN young WHEN ((cast(age#45 as int) >= 31) AND (cast(age#45 as int) <= 50)) THEN mid WHEN (cast(age#45 as int) > 51) THEN old ELSE kid END AS customer_group#57]\n",
      "         +- Filter (city#49 = boston)\n",
      "            +- Relation [cust_id#43,name#44,age#45,gender#46,birthday#47,zip#48,city#49] parquet\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "cust_id: string, name: string, age: string, gender: string, birthday: string, zip: string, city: string, customer_group: string, test_column_2: string, birth_month: string\n",
      "Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_2#649, split(birthday#47, /, -1)[1] AS birth_month#659]\n",
      "+- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_2 AS test_column_2#649]\n",
      "   +- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57]\n",
      "      +- Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, CASE WHEN ((cast(age#45 as int) >= 20) AND (cast(age#45 as int) <= 30)) THEN young WHEN ((cast(age#45 as int) >= 31) AND (cast(age#45 as int) <= 50)) THEN mid WHEN (cast(age#45 as int) > 51) THEN old ELSE kid END AS customer_group#57]\n",
      "         +- Filter (city#49 = boston)\n",
      "            +- Relation [cust_id#43,name#44,age#45,gender#46,birthday#47,zip#48,city#49] parquet\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_2 AS test_column_2#649, split(birthday#47, /, -1)[1] AS birth_month#659]\n",
      "+- InMemoryRelation [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "      +- *(1) Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, CASE WHEN ((cast(age#45 as int) >= 20) AND (cast(age#45 as int) <= 30)) THEN young WHEN ((cast(age#45 as int) >= 31) AND (cast(age#45 as int) <= 50)) THEN mid WHEN (cast(age#45 as int) > 51) THEN old ELSE kid END AS customer_group#57]\n",
      "         +- *(1) Filter (isnotnull(city#49) AND (city#49 = boston))\n",
      "            +- *(1) ColumnarToRow\n",
      "               +- FileScan parquet [cust_id#43,name#44,age#45,gender#46,birthday#47,zip#48,city#49] Batched: true, DataFilters: [isnotnull(city#49), (city#49 = boston)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/afaqueahmad/Documents/youtube/spark-experiments/data/data_..., PartitionFilters: [], PushedFilters: [IsNotNull(city), EqualTo(city,boston)], ReadSchema: struct<cust_id:string,name:string,age:string,gender:string,birthday:string,zip:string,city:string>\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57, test_column_2 AS test_column_2#649, split(birthday#47, /, -1)[1] AS birth_month#659]\n",
      "+- InMemoryTableScan [age#45, birthday#47, city#49, cust_id#43, customer_group#57, gender#46, name#44, zip#48]\n",
      "      +- InMemoryRelation [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, customer_group#57], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- *(1) Project [cust_id#43, name#44, age#45, gender#46, birthday#47, zip#48, city#49, CASE WHEN ((cast(age#45 as int) >= 20) AND (cast(age#45 as int) <= 30)) THEN young WHEN ((cast(age#45 as int) >= 31) AND (cast(age#45 as int) <= 50)) THEN mid WHEN (cast(age#45 as int) > 51) THEN old ELSE kid END AS customer_group#57]\n",
      "               +- *(1) Filter (isnotnull(city#49) AND (city#49 = boston))\n",
      "                  +- *(1) ColumnarToRow\n",
      "                     +- FileScan parquet [cust_id#43,name#44,age#45,gender#46,birthday#47,zip#48,city#49] Batched: true, DataFilters: [isnotnull(city#49), (city#49 = boston)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/afaqueahmad/Documents/youtube/spark-experiments/data/data_..., PartitionFilters: [], PushedFilters: [IsNotNull(city), EqualTo(city,boston)], ReadSchema: struct<cust_id:string,name:string,age:string,gender:string,birthday:string,zip:string,city:string>\n",
      "\n",
      "+----------+--------------+---+------+---------+-----+------+--------------+-------------+-----------+\n",
      "|cust_id   |name          |age|gender|birthday |zip  |city  |customer_group|test_column_2|birth_month|\n",
      "+----------+--------------+---+------+---------+-----+------+--------------+-------------+-----------+\n",
      "|C007YEYTX9|Aaron Abbott  |34 |Female|7/13/1991|97823|boston|mid           |test_column_2|13         |\n",
      "|C08XAQUY73|Aaron Lambert |54 |Female|11/5/1966|75218|boston|old           |test_column_2|5          |\n",
      "|C094P1VXF9|Aaron Lindsey |24 |Male  |9/21/1990|29399|boston|young         |test_column_2|21         |\n",
      "|C097SHE1EF|Aaron Lopez   |22 |Female|4/18/2001|82129|boston|young         |test_column_2|18         |\n",
      "|C0DTC6436T|Aaron Schwartz|52 |Female|7/9/1962 |57192|boston|old           |test_column_2|9          |\n",
      "+----------+--------------+---+------+---------+-----+------+--------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = (\n",
    "    df_base\n",
    "    .withColumn(\"test_column_2\", F.lit(\"test_column_2\"))\n",
    "    .withColumn(\"birth_month\", F.split(\"birthday\", \"/\").getItem(1))\n",
    ")\n",
    "\n",
    "df2.explain(True)\n",
    "df2.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `StorageLevel` Types:\n",
    "\n",
    "(As of Spark `3.4`)\n",
    "\n",
    "- `DISK_ONLY`: CPU efficient, memory efficient, slow to access, data is serialized when stored on disk\n",
    "- `DISK_ONLY_2`: disk only, replicated 2x\n",
    "- `DISK_ONLY_3`: disk only, replicated 3x\n",
    "\n",
    "- `MEMORY_AND_DISK`: spills to disk if there's no space in memory\n",
    "- `MEMORY_AND_DISK_2`: memory and disk, replicated 2x\n",
    "- `MEMORY_AND_DISK_DESER`(default): same as `MEMORY_AND_DISK`, deserialized in both for fast access\n",
    "\n",
    "- `MEMORY_ONLY`: CPU efficient, memory intensive\n",
    "- `MEMORY_ONLY_2`: memory only, replicated 2x - for resilience, if one executor fails\n",
    "\n",
    "**Note**: \n",
    "- `SER` is CPU intensive, memory saving as data is compact while `DESER` is CPU efficient, memory intensive\n",
    "- Size of data on disk is lesser as data is in serialized format, while deserialized in memory as JVM objects for faster access\n",
    "\n",
    "### When to use what?\n",
    "```\n",
    "Storage Level    Space used  CPU time  In memory  On-disk  Serialized\n",
    "---------------------------------------------------------------------\n",
    "MEMORY_ONLY          High        Low       Y          N        N         \n",
    "MEMORY_ONLY_SER      Low         High      Y          N        Y     \n",
    "MEMORY_AND_DISK      High        Medium    Some       Some     Some  \n",
    "MEMORY_AND_DISK_SER  Low         High      Some       Some     Y     \n",
    "DISK_ONLY            Low         High      N          Y        Y     \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.unpersist()\n",
    "df_base.persist(StorageLevel.MEMORY_ONLY)\n",
    "\n",
    "df2 = (\n",
    "    df_base\n",
    "    .withColumn(\"test_column_1\", F.lit(\"test_column_1\"))\n",
    "    .withColumn(\"birth_year\", F.split(\"birthday\", \"/\").getItem(2))\n",
    ")\n",
    "\n",
    "df1.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data-skew-explanation",
   "notebookOrigID": 4018749166498458,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
